Steps:
1- Create gama project
2- Install LMStudio, and execute an llm server on the port 1234
3- Execute serversock.py
4- Execute mainModel.gaml

Result:
1- In the console, you can observe the LLM calls with its inputs and outputs
2- In change_transport.txt and change_house.txt you can read the LLM's reasoning process
